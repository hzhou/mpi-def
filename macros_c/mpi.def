include: c/mpi_info.def
include: c/mpi_datatype.def

subcode: mpi_frame
    $include stdio
    $include stdlib
    $call @global
    $function main
        &call mpi_run
            $call main

subcode: _autoload
    $register_name(status) MPI_Status
    $register_prefix(comm) MPI_Comm
    $register_prefix(info) MPI_Info
    $register_prefix(req) MPI_Request
    $register_prefix(dt) MPI_Datatype

macros:
    mpi: 1
    tag: 0
    comm: MPI_COMM_WORLD
    rank: mpi_id
    size: mpi_size

    mpi_n1: MPI_BYTE
    mpi_n2: MPI_SHORT
    mpi_n4: MPI_INT
    mpi_n8: MPI_2INT
    mpi_f4: MPI_FLOAT
    mpi_f8: MPI_DOUBLE
    mpi_c16: MPI_LONG_DOUBLE

subcode: mpi_run
    $(if:!SKIP_SYSTEM_MPI)
        $include mpi
        $uselib mpi

    $global int mpi_size, int mpi_id
    MPI_Init(NULL, NULL)
    MPI_Comm_size($(comm), &mpi_size)
    MPI_Comm_rank($(comm), &mpi_id)

    $(if:0)
        $global char mpi_name[MPI_MAX_PROCESSOR_NAME]
        $local tn_len
        MPI_Get_processor_name(mpi_name, &tn_len)

    BLOCK

    $call @on_mpi_finalize
    MPI_Finalize()

#----------------------------------------
subcode: _autoload
    $plugin mpicall

# overwrite subcode mpicall to change the default error behavior
subcode:0 mpicall(fname, @params)
    $(fname)($(params))

#---------------------------------------- 
subcode: with_p2p(p1, p2)
    $if $(rank) == $(p1)
        $(set:is_p1=1)
        BLOCK
    $elif $(rank) == $(p2)
        $(set:is_p2=1)
        BLOCK

    # ---- example ----
    subcode: send_to(@data)
        &call parse_data
            $(if:is_p1)
                $call mpi_send, $(p2)
            $(else)
                $call mpi_recv, $(p1)

    subcode: send_back(@data)
        &call parse_data
            $(if:is_p1)
                $call mpi_recv, $(p2)
            $(else)
                $call mpi_send, $(p1)

    subcode: exchange(local, remote, size)
        $(set:data_src=$(local), $(size), MPI_BYTE)
        $(set:data_dst=$(remote), $(size), MPI_BYTE)
        $(if:is_p1)
            $call mpi_send, $(p2)
            $call mpi_recv, $(p2)
        $(else)
            $call mpi_recv, $(p1)
            $call mpi_send, $(p1)

subcode: ifelse_region(p0)
    $if $(rank) == $(p0)
        $(set:is_p1=1)
        BLOCK
    $else
        $(set:is_p2=1)
        BLOCK

subcode: ring_region
    # left and right
    $if $(rank) == 0
        $(set:is_first=1)
        $(set:_l=$(size)-1)
        $(set:_r=1)
        BLOCK
    $elif $(rank)==$(size)-1
        $(set:is_last=1)
        $(set:_l=$(rank)-1)
        $(set:_r=0)
        BLOCK
    $else
        $(set:is_middle=1)
        $(set:_l=$(rank)-1)
        $(set:_r=$(rank)+1)
        BLOCK

#---- shorthand ---------------------------------- 
subcode: parse_data
    $(split:data)
    $(if:p_n=3)
        #- buf, count, type
        $(set:data_src=$(data))
        $(set:data_dst=$(data))
    $(elif:p_n=4)
        #- src_buf, dst_buf, count, type
        $(set:data_src=$(p_1),$(p_3),$(p_4))
        $(set:data_dst=$(p_2),$(p_3),$(p_4))
    BLOCK

#---- pt2pt ----------------------------------- 
subcode: mpi_send(to)
    $(if:!data_src)
        $(set:data_src=$(data))
    $(if:!send)
        $(set:send=send)

    $(if:send=send or send=bsend or send=rsend or send=ssend)
        $mpicall MPI_$(send:ucfirst), $(data_src), $(to), $(tag), $(comm)
    $(else)
        $mpicall MPI_$(send:ucfirst), $(data_src), $(to), $(tag), $(comm), &$(req)

subcode: mpi_recv(from)
    $(if:!data_dst)
        $(set:data_dst=$(data))
    $(if:!recv)
        $(set:recv=recv)

    $(if:recv!=recv)
        $(set:tail=&$(req))
    $(elif:status)
        $(set:tail=&$(status))
    $(else)
        $(set:tail=MPI_STATUS_IGNORE)

    $mpicall MPI_$(recv:ucfirst), $(data_dst), $(from), $(tag), $(comm), $(tail)

subcode: mpi_wait
    $(if:status)
        $mpicall MPI_Wait, &$(req), &$(status)
    $(else)
        $mpicall MPI_Wait, &$(req), MPI_STATUS_IGNORE

subcode: mpi_waitany(N, reqs, idx)
    $my int idx = 0
    $(if:status)
        $mpicall MPI_Waitany, $(N), $(reqs), &idx, &$(status)
    $(else)
        $mpicall MPI_Waitany, $(N), $(reqs), &idx, MPI_STATUS_IGNORE

#---- collectives ----------------------------------- 
subcode: mpi_barrier
    MPI_Barrier($(comm))

subcode: mpi_bcast
    $(if:!root)
        $(set:root=0)
    MPI_Bcast($(data), $(root), $(comm))

subcode: mpi_reduce_sum(var)
    $(if:!root)
        $(set:root=0)
    $if $(rank) == $(root)
        $mpicall MPI_Reduce, MPI_IN_PLACE, &$(var), 1, MPI_INT, MPI_SUM, 0, $(comm)
    $else
        $mpicall MPI_Reduce, &$(var), NULL, 1, MPI_INT, MPI_SUM, 0, $(comm)


#---- onesided ---------------------------- 
#- implicit: $(data), $(win)
subcode: _autoload
    $register_name(win) MPI_Win

subcode: mpi_win_allocate(size)
    $global MPI_Win win, void *mpi_base
    MPI_Win_allocate($(size), 1, MPI_INFO_NULL, $(comm), &mpi_base, &win)
    $(setmacro:win=win)

subcode: mpi_put(tgt, offset)
    $(split:data)
    MPI_Win_lock(MPI_LOCK_EXCLUSIVE, $(tgt), 0, $(win))
    MPI_Put($(data), $(tgt), $(offset), $(p_2), $(p_3), $(win))
    MPI_Win_unlock($(tgt), $(win))

subcode:: on_mpi_finalize
    $(if:win=win)
        MPI_Win_free(&$(win))

#---- convenience ---------------------------- 
subcode: hello
    $print Hello, $mpi_id/$mpi_size

#--------------------------------------------- 
subcode: debug_hook(cond)
    $include unistd
    $if $(cond)
        $print "mpi [$$(rank)] PID %d is ready for attach ...", getpid()
        $local int debug_i=0
        $while debug_i == 0
            sleep(5)
